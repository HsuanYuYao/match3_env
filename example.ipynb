{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_match3.envs import Match3Env\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "# import pickle\n",
    "from matplotlib import style\n",
    "#from gym_match3.envs.levels import Match3Levels, Level\n",
    "env = Match3Env()\n",
    "obs, reward, done, info = env.step(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({(0, 1), (1, 1)}),\n",
       " frozenset({(4, 4), (5, 4)}),\n",
       " frozenset({(5, 3), (5, 4)}),\n",
       " frozenset({(7, 2), (7, 3)}),\n",
       " frozenset({(4, 7), (5, 7)}),\n",
       " frozenset({(4, 5), (4, 6)}),\n",
       " frozenset({(0, 5), (1, 5)}),\n",
       " frozenset({(1, 0), (2, 0)}),\n",
       " frozenset({(2, 2), (3, 2)}),\n",
       " frozenset({(5, 3), (6, 3)}),\n",
       " frozenset({(0, 0), (1, 0)}),\n",
       " frozenset({(2, 5), (2, 6)}),\n",
       " frozenset({(4, 1), (4, 2)}),\n",
       " frozenset({(5, 0), (6, 0)}),\n",
       " frozenset({(2, 0), (2, 1)}),\n",
       " frozenset({(7, 0), (7, 1)}),\n",
       " frozenset({(2, 7), (3, 7)}),\n",
       " frozenset({(3, 4), (4, 4)}),\n",
       " frozenset({(5, 6), (5, 7)}),\n",
       " frozenset({(6, 5), (7, 5)}),\n",
       " frozenset({(6, 7), (7, 7)}),\n",
       " frozenset({(4, 1), (5, 1)}),\n",
       " frozenset({(0, 4), (0, 5)}),\n",
       " frozenset({(1, 3), (1, 4)}),\n",
       " frozenset({(1, 6), (2, 6)}),\n",
       " frozenset({(0, 7), (1, 7)}),\n",
       " frozenset({(3, 0), (3, 1)}),\n",
       " frozenset({(4, 2), (5, 2)}),\n",
       " frozenset({(3, 3), (3, 4)}),\n",
       " frozenset({(2, 3), (3, 3)}),\n",
       " frozenset({(5, 1), (5, 2)}),\n",
       " frozenset({(3, 1), (3, 2)}),\n",
       " frozenset({(0, 3), (1, 3)}),\n",
       " frozenset({(6, 3), (6, 4)}),\n",
       " frozenset({(6, 1), (7, 1)}),\n",
       " frozenset({(3, 0), (4, 0)}),\n",
       " frozenset({(3, 4), (3, 5)}),\n",
       " frozenset({(5, 4), (6, 4)}),\n",
       " frozenset({(3, 7), (4, 7)}),\n",
       " frozenset({(4, 4), (4, 5)}),\n",
       " frozenset({(2, 4), (2, 5)}),\n",
       " frozenset({(3, 6), (3, 7)}),\n",
       " frozenset({(5, 2), (6, 2)}),\n",
       " frozenset({(5, 6), (6, 6)}),\n",
       " frozenset({(1, 7), (2, 7)}),\n",
       " frozenset({(4, 0), (5, 0)}),\n",
       " frozenset({(6, 4), (7, 4)}),\n",
       " frozenset({(7, 1), (7, 2)}),\n",
       " frozenset({(0, 0), (0, 1)}),\n",
       " frozenset({(1, 4), (1, 5)}),\n",
       " frozenset({(0, 6), (0, 7)}),\n",
       " frozenset({(3, 6), (4, 6)}),\n",
       " frozenset({(2, 0), (3, 0)}),\n",
       " frozenset({(3, 5), (3, 6)}),\n",
       " frozenset({(4, 2), (4, 3)}),\n",
       " frozenset({(1, 5), (1, 6)}),\n",
       " frozenset({(2, 5), (3, 5)}),\n",
       " frozenset({(3, 3), (4, 3)}),\n",
       " frozenset({(6, 1), (6, 2)}),\n",
       " frozenset({(6, 6), (7, 6)}),\n",
       " frozenset({(2, 4), (3, 4)}),\n",
       " frozenset({(6, 4), (6, 5)}),\n",
       " frozenset({(2, 3), (2, 4)}),\n",
       " frozenset({(7, 4), (7, 5)}),\n",
       " frozenset({(6, 6), (6, 7)}),\n",
       " frozenset({(7, 3), (7, 4)}),\n",
       " frozenset({(4, 5), (5, 5)}),\n",
       " frozenset({(0, 3), (0, 4)}),\n",
       " frozenset({(2, 6), (2, 7)}),\n",
       " frozenset({(6, 0), (6, 1)}),\n",
       " frozenset({(2, 1), (3, 1)}),\n",
       " frozenset({(5, 5), (6, 5)}),\n",
       " frozenset({(5, 4), (5, 5)}),\n",
       " frozenset({(0, 5), (0, 6)}),\n",
       " frozenset({(1, 0), (1, 1)}),\n",
       " frozenset({(4, 6), (4, 7)}),\n",
       " frozenset({(4, 3), (5, 3)}),\n",
       " frozenset({(7, 6), (7, 7)}),\n",
       " frozenset({(6, 3), (7, 3)}),\n",
       " frozenset({(0, 6), (1, 6)}),\n",
       " frozenset({(5, 0), (5, 1)}),\n",
       " frozenset({(0, 1), (0, 2)}),\n",
       " frozenset({(7, 5), (7, 6)}),\n",
       " frozenset({(6, 2), (7, 2)}),\n",
       " frozenset({(0, 2), (1, 2)}),\n",
       " frozenset({(2, 2), (2, 3)}),\n",
       " frozenset({(0, 2), (0, 3)}),\n",
       " frozenset({(1, 4), (2, 4)}),\n",
       " frozenset({(6, 0), (7, 0)}),\n",
       " frozenset({(5, 1), (6, 1)}),\n",
       " frozenset({(2, 1), (2, 2)}),\n",
       " frozenset({(1, 1), (1, 2)}),\n",
       " frozenset({(5, 5), (5, 6)}),\n",
       " frozenset({(2, 6), (3, 6)}),\n",
       " frozenset({(4, 3), (4, 4)}),\n",
       " frozenset({(6, 2), (6, 3)}),\n",
       " frozenset({(4, 6), (5, 6)}),\n",
       " frozenset({(6, 5), (6, 6)}),\n",
       " frozenset({(0, 4), (1, 4)}),\n",
       " frozenset({(1, 2), (1, 3)}),\n",
       " frozenset({(1, 1), (2, 1)}),\n",
       " frozenset({(4, 0), (4, 1)}),\n",
       " frozenset({(1, 2), (2, 2)}),\n",
       " frozenset({(5, 2), (5, 3)}),\n",
       " frozenset({(1, 5), (2, 5)}),\n",
       " frozenset({(1, 3), (2, 3)}),\n",
       " frozenset({(1, 6), (1, 7)}),\n",
       " frozenset({(3, 5), (4, 5)}),\n",
       " frozenset({(3, 2), (3, 3)}),\n",
       " frozenset({(3, 2), (4, 2)}),\n",
       " frozenset({(5, 7), (6, 7)}),\n",
       " frozenset({(3, 1), (4, 1)})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(env.get_directions(2))\n",
    "env.get_available_actions()   #查看action對應的動作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (2, 4)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(env.get_available_actions()[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5fe11d5e0630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m220\u001b[0m \u001b[0;31m# percent of original size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "scale_percent = 220 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_obs(observation=None):\n",
    "    \n",
    "    d = {0: (255, 255, 255),   #白色\n",
    "     1: (0, 255, 255),      #黃色\n",
    "     2: (0, 0, 255) ,      #紅色\n",
    "     3: (230,224,176) ,   #灰藍色 \n",
    "     4: (0,0,0)}           #黑色    \n",
    "    \n",
    "    \n",
    "    background = np.zeros((5,8,3), dtype=np.uint8) #黑色的背景\n",
    "\n",
    "    for color in range(5):\n",
    "        result = np.where(observation == color)\n",
    "        \n",
    "        listOfCoordinates= list(zip(result[0], result[1]))\n",
    "        \n",
    "        for cord in listOfCoordinates:\n",
    "            background[cord] = d[color]     \n",
    "            \n",
    "    img = Image.fromarray(background, 'RGB')\n",
    "     \n",
    "    \n",
    "    #img = img.resize((500, 800)) \n",
    "    cv2.imshow(\"image\", np.array(img))\n",
    "    \n",
    "    cv2.waitKey(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 5, (1, 8, 8), int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Match3Env() \n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "---------------\n",
      "(1, 8, 8)\n",
      "Episode finished after 10 timesteps\n"
     ]
    }
   ],
   "source": [
    "from gym_match3.envs import Match3Env\n",
    "import gym\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "d = {0: (255, 255, 255),   #白色\n",
    "     1: (0, 255, 255),      #黃色\n",
    "     2: (0, 0, 255) ,      #紅色\n",
    "     3: (230,224,176) ,   #灰藍色 \n",
    "     4: (0,0,0)}           #黑色    \n",
    "\n",
    "\n",
    "env = Match3Env() \n",
    "for i_episode in range(10): #玩一次遊戲\n",
    "    observation = env.reset()\n",
    "    for t in range(10):  #做10個 action\n",
    "        #print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        #print('action: ',action)\n",
    "        print('---------------')\n",
    "        #print('the swap of coordinate is: ',list(env.get_available_actions()[action]))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        print(observation.shape)\n",
    "        #print()\n",
    "        #print(observation)\n",
    "        #print(i)\n",
    "    #plot_obs(observation)\n",
    "                \n",
    "        #print('reward:', reward)\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_match3.envs import Match3Env\n",
    "import gym\n",
    "env = Match3Env()\n",
    "obs, reward, done, info = env.step(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.autograd import Variable\n",
    "from itertools import count\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 24)\n",
    "        self.fc2 = nn.Linear(24, 36)\n",
    "        self.fc3 = nn.Linear(36, 1)  # Prob of Left\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Plot duration curve: \n",
    "    # From http://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "    episode_durations = []\n",
    "    def plot_durations():\n",
    "        plt.figure(2)\n",
    "        plt.clf()\n",
    "        durations_t = torch.FloatTensor(episode_durations)\n",
    "        plt.title('Training...')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Duration')\n",
    "        plt.plot(durations_t.numpy())\n",
    "        # Take 100 episode averages and plot them too\n",
    "        if len(durations_t) >= 100:\n",
    "            means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "            means = torch.cat((torch.zeros(99), means))\n",
    "            plt.plot(means.numpy())\n",
    "\n",
    "        plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "    # Parameters\n",
    "    num_episode = 5000\n",
    "    batch_size = 5\n",
    "    learning_rate = 0.01\n",
    "    gamma = 0.99\n",
    "\n",
    "    env = gym.make('CartPole-v0')\n",
    "    policy_net = PolicyNet()\n",
    "    optimizer = torch.optim.RMSprop(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Batch History\n",
    "    state_pool = []\n",
    "    action_pool = []\n",
    "    reward_pool = []\n",
    "    steps = 0\n",
    "\n",
    "\n",
    "    for e in range(num_episode):\n",
    "\n",
    "        state = env.reset()\n",
    "        state = torch.from_numpy(state).float()\n",
    "        state = Variable(state)\n",
    "        env.render(mode='rgb_array')\n",
    "\n",
    "        for t in count():\n",
    "\n",
    "            probs = policy_net(state)\n",
    "            m = Bernoulli(probs)\n",
    "            action = m.sample()\n",
    "\n",
    "            action = action.data.numpy().astype(int)[0]\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            env.render(mode='rgb_array')\n",
    "\n",
    "            # To mark boundarys between episodes\n",
    "            if done:\n",
    "                reward = 0\n",
    "\n",
    "            state_pool.append(state)\n",
    "            action_pool.append(float(action))\n",
    "            reward_pool.append(reward)\n",
    "\n",
    "            state = next_state\n",
    "            state = torch.from_numpy(state).float()\n",
    "            state = Variable(state)\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done:\n",
    "                episode_durations.append(t + 1)\n",
    "                plot_durations()\n",
    "                break\n",
    "\n",
    "        # Update policy\n",
    "        if e > 0 and e % batch_size == 0:\n",
    "\n",
    "            # Discount reward\n",
    "            running_add = 0\n",
    "            for i in reversed(range(steps)):\n",
    "                if reward_pool[i] == 0:\n",
    "                    running_add = 0\n",
    "                else:\n",
    "                    running_add = running_add * gamma + reward_pool[i]\n",
    "                    reward_pool[i] = running_add\n",
    "\n",
    "            # Normalize reward\n",
    "            reward_mean = np.mean(reward_pool)\n",
    "            reward_std = np.std(reward_pool)\n",
    "            for i in range(steps):\n",
    "                reward_pool[i] = (reward_pool[i] - reward_mean) / reward_std\n",
    "\n",
    "            # Gradient Desent\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            for i in range(steps):\n",
    "                state = state_pool[i]\n",
    "                action = Variable(torch.FloatTensor([action_pool[i]]))\n",
    "                reward = reward_pool[i]\n",
    "\n",
    "                probs = policy_net(state)\n",
    "                m = Bernoulli(probs)\n",
    "                loss = -m.log_prob(action) * reward  # Negtive score function x reward\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            state_pool = []\n",
    "            action_pool = []\n",
    "            reward_pool = []\n",
    "            steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/anaconda3/envs/yourenvname/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ImageData' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-8ebfa592d618>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yourenvname/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yourenvname/lib/python3.6/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/yourenvname/lib/python3.6/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_buffer_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_color_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;31m# In https://github.com/openai/gym-http-api/issues/2, we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;31m# discovered that someone using Xmonad on Arch was having\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageData' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.core import Processor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE + (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 32, 2, 3)          320       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 32, 2, 64)         256       \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 67)                34371     \n",
      "=================================================================\n",
      "Total params: 2,132,611\n",
      "Trainable params: 2,132,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, Input\n",
    "NUM_FILTERS_LAYER_1 = 512\n",
    "NUM_FILTERS_LAYER_2 = 4096\n",
    "NUM_FILTERS_LAYER_1 = 32 # number of filters in 1st layer\n",
    "NUM_FILTERS_LAYER_2 = 64 # number of filters in 2nd layer\n",
    "FILTERS_SIZE_LAYER_1 = 3 # Filter Size = 3 x 3\n",
    "FILTERS_SIZE_LAYER_2 = 1 # Filter Size = 1 x 1\n",
    "STRIDES_LAYER_1 = (2, 2)\n",
    "STRIDES_LAYER_2 = (1, 1)\n",
    "ACTIVATION_FTN_CNN = 'relu'\n",
    "# Dense Layers:\n",
    "NUM_DENSE_NEURONS = 512\n",
    "ACTIVATION_FTN_DENSE = 'relu'\n",
    "ACTIVATION_FTN_OUTPUT = 'linear'\n",
    "NUM_ACTIONS_OUTPUT_NN = env.action_space.n \n",
    "\n",
    "INPUT_SHAPE = (5,8)\n",
    "\n",
    "INPUT_SHAPE_CNN =  (1,) +  INPUT_SHAPE\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=NUM_FILTERS_LAYER_1,\n",
    "         kernel_size=FILTERS_SIZE_LAYER_1,\n",
    "         strides=STRIDES_LAYER_1,\n",
    "         padding='valid',\n",
    "         activation=ACTIVATION_FTN_CNN,\n",
    "         input_shape=INPUT_SHAPE_CNN , data_format='channels_first')) #, data_format=data_format)) \n",
    "model.add(Conv2D(filters=NUM_FILTERS_LAYER_2,\n",
    "         kernel_size=FILTERS_SIZE_LAYER_2,\n",
    "         strides=STRIDES_LAYER_2,\n",
    "         padding='valid',\n",
    "         activation=ACTIVATION_FTN_CNN,\n",
    "         input_shape=INPUT_SHAPE_CNN)) #, data_format=data_format))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=NUM_DENSE_NEURONS, activation=ACTIVATION_FTN_DENSE))\n",
    "model.add(Dense(units=NUM_ACTIONS_OUTPUT_NN, activation=ACTIVATION_FTN_OUTPUT))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_43/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 1, 1], use_cudnn_on_gpu=true](input_7, conv2d_43/Conv2D/ReadVariableOp)' with input shapes: [?,1,5,8], [3,3,8,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1811\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_43/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 1, 1], use_cudnn_on_gpu=true](input_7, conv2d_43/Conv2D/ReadVariableOp)' with input shapes: [?,1,5,8], [3,3,8,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-d1b80322c1ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINPUT_SHAPE_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mconv_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_FILTERS_LAYER_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFILTERS_SIZE_LAYER_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mACTIVATION_FTN_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mconv_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_FILTERS_LAYER_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFILTERS_SIZE_LAYER_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mACTIVATION_FTN_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mconv_aa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_FILTERS_LAYER_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFILTERS_SIZE_LAYER_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mACTIVATION_FTN_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m               \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2590\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2593\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2594\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    977\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    980\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3483\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3486\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1975\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_43/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 2, 1, 1], use_cudnn_on_gpu=true](input_7, conv2d_43/Conv2D/ReadVariableOp)' with input shapes: [?,1,5,8], [3,3,8,32]."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "INPUT_SHAPE_CNN =  (1,) +  INPUT_SHAPE\n",
    "\n",
    "_input = Input(shape=INPUT_SHAPE_CNN)\n",
    "conv_a = Conv2D(filters=NUM_FILTERS_LAYER_1, kernel_size=FILTERS_SIZE_LAYER_1, strides=(2,1), padding='valid', activation=ACTIVATION_FTN_CNN)(_input)\n",
    "conv_b = Conv2D(filters=NUM_FILTERS_LAYER_1, kernel_size=FILTERS_SIZE_LAYER_1, strides=(1,2), padding='valid', activation=ACTIVATION_FTN_CNN)(_input)\n",
    "conv_aa = Conv2D(filters=NUM_FILTERS_LAYER_2, kernel_size=FILTERS_SIZE_LAYER_2, strides=(2,1), padding='valid', activation=ACTIVATION_FTN_CNN)(conv_a)\n",
    "conv_ab = Conv2D(filters=NUM_FILTERS_LAYER_2, kernel_size=FILTERS_SIZE_LAYER_2, strides=(1,2), padding='valid', activation=ACTIVATION_FTN_CNN)(conv_a)\n",
    "conv_ba = Conv2D(filters=NUM_FILTERS_LAYER_2, kernel_size=FILTERS_SIZE_LAYER_2, strides=(2,1), padding='valid', activation=ACTIVATION_FTN_CNN)(conv_b)\n",
    "conv_bb = Conv2D(filters=NUM_FILTERS_LAYER_2, kernel_size=FILTERS_SIZE_LAYER_2, strides=(1,2), padding='valid', activation=ACTIVATION_FTN_CNN)(conv_b)\n",
    "merge = concatenate([Flatten()(x) for x in [conv_aa, conv_ab, conv_ba, conv_bb, conv_a, conv_b]])\n",
    "_output = Dense(units=NUM_ACTIONS_OUTPUT_NN, activation='linear')(merge)\n",
    "model = Model(inputs=_input, outputs=_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=MEMORY_SIZE, window_length=WINDOW_LENGTH)\n",
    "TRAIN_POLICY = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=0.05, value_min=0.05, value_test=0.01, nb_steps=NB_STEPS_ANNEALED)\n",
    "TEST_POLICY = EpsGreedyQPolicy(eps=.01)\n",
    "dqn = DQNAgent(model=model, nb_actions=NUM_ACTIONS_OUTPUT_NN, test_policy=TEST_POLICY, policy=TRAIN_POLICY, memory=memory)\n",
    "\n",
    "# Training Method & Metric:\n",
    "#    We use the Adam learning method with MSE (mean squared error) metric.\n",
    "dqn.compile(Adam(lr=.00025), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              41984     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 67)                17219     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 67)                0         \n",
      "=================================================================\n",
      "Total params: 715,331\n",
      "Trainable params: 715,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "#env = gym.make(ENV_NAME)\n",
    "\n",
    "#env.seed(123)\n",
    "nb_actions = env.action_space.n\n",
    "\n",
    "# Next, we build a very simple model.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())\n",
    "\n",
    "NUM_ACTIONS_OUTPUT_NN = env.action_space.n \n",
    "MEMORY_SIZE = 6000 \n",
    "WINDOW_LENGTH = 1\n",
    "NB_STEPS_ANNEALED = int(1e5)\n",
    "NB_STEPS_WARMUP = 5000\n",
    "TARGET_MODEL_UPDATE = 1000\n",
    "\n",
    "\n",
    "#BATCH_SIZE\n",
    "#processor = Log2NNInputProcessor()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "memory = SequentialMemory(limit=MEMORY_SIZE, window_length=WINDOW_LENGTH)\n",
    "TRAIN_POLICY = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=0.05, value_min=0.05, value_test=0.01, nb_steps=NB_STEPS_ANNEALED)\n",
    "TEST_POLICY = EpsGreedyQPolicy(eps=.01)\n",
    "dqn = DQNAgent(model=model, nb_actions=NUM_ACTIONS_OUTPUT_NN, test_policy=TEST_POLICY, policy=TRAIN_POLICY, memory=memory)\n",
    "\n",
    "# Training Method & Metric:\n",
    "#    We use the Adam learning method with MSE (mean squared error) metric.\n",
    "dqn.compile(Adam(lr=.00025), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: -11.000, steps: 11\n",
      "Episode 2: reward: -82.000, steps: 100\n",
      "Episode 3: reward: -100.000, steps: 100\n",
      "Episode 4: reward: -100.000, steps: 100\n",
      "Episode 5: reward: -100.000, steps: 100\n",
      "Episode 6: reward: -100.000, steps: 100\n",
      "Episode 7: reward: -85.000, steps: 100\n",
      "Episode 8: reward: -100.000, steps: 100\n",
      "Episode 9: reward: -100.000, steps: 100\n",
      "Episode 10: reward: -100.000, steps: 100\n",
      "-11.0\n"
     ]
    }
   ],
   "source": [
    "scores = dqn.test(env, nb_episodes=10, visualize=False)\n",
    "\n",
    "print(np.max(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
